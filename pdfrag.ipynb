{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuNxbhiEXQgH62h7hG7acp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhanush-sai-reddy/langchain/blob/main/pdfrag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain langchain-text-splitters langchain-community bs4"
      ],
      "metadata": {
        "id": "BWGQadH40JC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U \"langchain[huggingface]\""
      ],
      "metadata": {
        "id": "S-7PbGaQ1t_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"hf_...\"\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"microsoft/Phi-3-mini-4k-instruct\",\n",
        "    temperature=0.7,\n",
        "\n",
        ")\n",
        "model = ChatHuggingFace(llm=llm)"
      ],
      "metadata": {
        "id": "sd1PpVzp13jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU langchain-huggingface\n"
      ],
      "metadata": {
        "id": "8ViqQ59t13i-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "file_path = \"/content/FLAP-SAM.pdf\"\n",
        "loader = PyPDFLoader(file_path)\n",
        "\n",
        "docs = loader.load()\n",
        "\n",
        "print(len(docs))"
      ],
      "metadata": {
        "id": "ppaYQcFe2cDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
        ")\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "\n",
        "print(len(all_splits))"
      ],
      "metadata": {
        "id": "RQBtu65a2njp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
      ],
      "metadata": {
        "id": "_1C7m5zm2nh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SbpgxQYA2cCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "\n",
        "vector_store = InMemoryVectorStore(embeddings)"
      ],
      "metadata": {
        "id": "YdF2Zsa22XED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "@tool(response_format=\"content_and_artifact\")\n",
        "def retrieve_context(query: str):\n",
        "    \"\"\"Retrieve information to help answer a query.\"\"\"\n",
        "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
        "    serialized = \"\\n\\n\".join(\n",
        "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
        "        for doc in retrieved_docs\n",
        "    )\n",
        "    return serialized, retrieved_docs"
      ],
      "metadata": {
        "id": "tC-hYvk92PWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_agent"
      ],
      "metadata": {
        "id": "GpNGavEU32Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools=[retrieve_context]\n",
        "prompt = (\n",
        "    \"You have access to a tool that retrieves context from a blog post. \"\n",
        "    \"Use the tool to help answer user queries.\"\n",
        ")\n",
        "agent = create_agent(model, tools, system_prompt=prompt)"
      ],
      "metadata": {
        "id": "hJOF6Iu532Om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = (\n",
        "    \"What is the communication cost reduction achieved\\n\\n\"\n",
        "    \"what is lora \"\n",
        ")\n",
        "\n",
        "for event in agent.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    event[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "id": "DbLVXEcH7D1X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}